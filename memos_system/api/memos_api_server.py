# memos_api_server.py - MemOS FastAPI æœåŠ¡ï¼ˆç®€åŒ–ç‰ˆï¼‰
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Optional, Any
import uvicorn
import json
import os
import re
import asyncio
from datetime import datetime
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import torch

app = FastAPI(title="MemOS API for è‚¥ç‰›AI", version="1.0.0")

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
embedding_model = None
memory_store = []  # ç®€å•çš„å†…å­˜å­˜å‚¨
USER_ID = "feiniu_default"
llm_config = None  # LLM é…ç½®ï¼ˆç”¨äºè®°å¿†åŠ å·¥ï¼‰
full_config = None  # å®Œæ•´é…ç½®ï¼ˆåŒ…å«å¤‡ç”¨æ¨¡å‹ç­‰ï¼‰


# è¯·æ±‚æ¨¡å‹
class AddMemoryRequest(BaseModel):
    messages: List[Dict[str, str]]
    user_id: Optional[str] = USER_ID


# ğŸ”¥ ç›´æ¥å­˜å‚¨çš„æ¶ˆæ¯æ ¼å¼ï¼ˆæ”¯æŒæµ®ç‚¹æ•° importanceï¼‰
class RawMemoryMessage(BaseModel):
    content: str
    role: Optional[str] = "user"
    importance: Optional[float] = 0.8


class AddRawMemoryRequest(BaseModel):
    messages: List[RawMemoryMessage]
    user_id: Optional[str] = USER_ID


class SearchMemoryRequest(BaseModel):
    query: str
    top_k: Optional[int] = 3
    user_id: Optional[str] = USER_ID
    similarity_threshold: Optional[float] = 0.5  # ğŸ”¥ ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„è®°å¿†ä¸è¿”å›


class MigrateRequest(BaseModel):
    file_path: str


# åˆå§‹åŒ–
@app.on_event("startup")
async def startup_event():
    global embedding_model, memory_store, llm_config, full_config
    
    print("ğŸš€ å¯åŠ¨ MemOS æœåŠ¡ï¼ˆç®€åŒ–ç‰ˆï¼‰...")
    
    try:
        # åŠ è½½ LLM é…ç½®ï¼ˆç”¨äºè®°å¿†åŠ å·¥ï¼‰
        config_path = os.path.join(os.path.dirname(__file__), "..", "config", "memos_config.json")
        print(f"ğŸ“‚ é…ç½®æ–‡ä»¶è·¯å¾„: {config_path}")
        
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                full_config = config  # ä¿å­˜å®Œæ•´é…ç½®ï¼ˆå«å¤‡ç”¨æ¨¡å‹ï¼‰
                llm_config = config.get('llm', {}).get('config', {})
                
                # éªŒè¯é…ç½®å®Œæ•´æ€§
                if llm_config and all(llm_config.get(k) for k in ['model', 'api_key', 'base_url']):
                    print(f"âœ… åŠ è½½ LLM é…ç½®æˆåŠŸ:")
                    print(f"   - model: {llm_config.get('model')}")
                    print(f"   - base_url: {llm_config.get('base_url')}")
                    print(f"   - api_key: {llm_config.get('api_key')[:10]}...")
                else:
                    print("âš ï¸ LLM é…ç½®ä¸å®Œæ•´ï¼è®°å¿†åŠ å·¥åŠŸèƒ½å°†ä¸å¯ç”¨")
                    print(f"   å½“å‰é…ç½®: {llm_config}")
        else:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            print("   è®°å¿†åŠ å·¥åŠŸèƒ½å°†ä¸å¯ç”¨")
        
        # åŠ è½½ embedding æ¨¡å‹
        print("ğŸ“¦ åŠ è½½ Embedding æ¨¡å‹: ../../RAG-model")
        rag_model_path = os.path.join(os.path.dirname(__file__), "..", "..", "RAG-model")
        embedding_model = SentenceTransformer(rag_model_path)
        
        # ä½¿ç”¨ GPU åŠ é€Ÿ
        if torch.cuda.is_available():
            embedding_model = embedding_model.to('cuda')
            print("âœ… ä½¿ç”¨ GPU åŠ é€Ÿ")
        else:
            print("â„¹ï¸ ä½¿ç”¨ CPU")
        
        # åŠ è½½å·²å­˜åœ¨çš„è®°å¿†ï¼ˆå¦‚æœæœ‰ï¼‰
        data_dir = os.path.join(os.path.dirname(__file__), "..", "data")
        os.makedirs(data_dir, exist_ok=True)
        memory_file = os.path.join(data_dir, "memory_store.json")
        
        if os.path.exists(memory_file):
            try:
                with open(memory_file, 'r', encoding='utf-8') as f:
                    memory_store = json.load(f)
                print(f"âœ… åŠ è½½äº† {len(memory_store)} æ¡å†å²è®°å¿†")
            except json.JSONDecodeError as e:
                print(f"âš ï¸ è®°å¿†æ–‡ä»¶æŸå: {e}")
                print("ğŸ”§ å°è¯•ä¿®å¤...")
                
                # å°è¯•ä¿®å¤æŸåçš„ JSON
                try:
                    with open(memory_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡
                    # æŸ¥æ‰¾æœ€åä¸€ä¸ª "}," æˆ– "}" å¹¶æˆªæ–­
                    last_valid = -1
                    bracket_count = 0
                    in_string = False
                    escape_next = False
                    
                    for i, char in enumerate(content):
                        if escape_next:
                            escape_next = False
                            continue
                        if char == '\\':
                            escape_next = True
                            continue
                        if char == '"' and not escape_next:
                            in_string = not in_string
                            continue
                        if in_string:
                            continue
                        if char == '{':
                            bracket_count += 1
                        elif char == '}':
                            bracket_count -= 1
                            if bracket_count == 1:  # å›åˆ°æ•°ç»„çº§åˆ«
                                last_valid = i + 1
                    
                    if last_valid > 0:
                        # æˆªæ–­åˆ°æœ€åä¸€ä¸ªæœ‰æ•ˆä½ç½®å¹¶æ·»åŠ ç»“å°¾
                        fixed_content = content[:last_valid] + "\n]"
                        memory_store = json.loads(fixed_content)
                        
                        # å¤‡ä»½æŸåæ–‡ä»¶
                        backup_file = memory_file + f".broken_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                        import shutil
                        shutil.copy(memory_file, backup_file)
                        print(f"ğŸ“¦ å·²å¤‡ä»½æŸåæ–‡ä»¶åˆ°: {backup_file}")
                        
                        # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
                        with open(memory_file, 'w', encoding='utf-8') as f:
                            json.dump(memory_store, f, ensure_ascii=False, indent=2)
                        
                        print(f"âœ… ä¿®å¤æˆåŠŸï¼æ¢å¤äº† {len(memory_store)} æ¡è®°å¿†")
                    else:
                        raise ValueError("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„è®°å¿†æ•°æ®")
                        
                except Exception as repair_error:
                    print(f"âŒ ä¿®å¤å¤±è´¥: {repair_error}")
                    # å¤‡ä»½å¹¶åˆ›å»ºæ–°æ–‡ä»¶
                    backup_file = memory_file + f".broken_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    import shutil
                    shutil.copy(memory_file, backup_file)
                    print(f"ğŸ“¦ å·²å¤‡ä»½æŸåæ–‡ä»¶åˆ°: {backup_file}")
                    print("â„¹ï¸ åˆ›å»ºæ–°çš„è®°å¿†å­˜å‚¨")
                    memory_store = []
        else:
            print("â„¹ï¸ åˆ›å»ºæ–°çš„è®°å¿†å­˜å‚¨")
        
        print("âœ… MemOS æœåŠ¡å¯åŠ¨æˆåŠŸ!")
        print(f"ğŸ“ å‘é‡å­˜å‚¨è·¯å¾„: ./memos_system/data")
        print(f"ğŸ§  Embedding æ¨¡å‹: ./RAG-model")
        print(f"ğŸ¤– è®°å¿†åŠ å·¥ LLM: {llm_config.get('model', 'N/A') if llm_config else 'æœªé…ç½®'}")
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise


async def process_memory_with_llm(content: str, role: str = "user") -> dict:
    """ä½¿ç”¨ LLM åŠ å·¥è®°å¿†ï¼šæå–å…³é”®ä¿¡æ¯å¹¶ç»“æ„åŒ–ï¼ŒåŒæ—¶åˆ¤æ–­é‡è¦åº¦
    
    Args:
        content: å¯¹è¯å†…å®¹
        role: å‘è¨€è€…è§’è‰² - "user"è¡¨ç¤ºä½¿ç”¨è€…ï¼ˆä¸»äººï¼‰ï¼Œ"assistant"è¡¨ç¤ºAIï¼ˆè‚¥ç‰›ï¼‰
    
    Returns:
        dict: {"content": åŠ å·¥åçš„å†…å®¹, "importance": é‡è¦åº¦0.1-1.0}
    """
    global llm_config
    
    if not llm_config:
        print("âš ï¸ LLM æœªé…ç½®ï¼Œè·³è¿‡è®°å¿†åŠ å·¥")
        return {"content": content, "importance": 0.5}
    
    # æå–å¹¶éªŒè¯ LLM é…ç½®
    api_key = llm_config.get('api_key', '')
    model = llm_config.get('model', '')
    base_url = llm_config.get('base_url', '')
    
    if not api_key or not model or not base_url:
        print(f"âš ï¸ LLM é…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡è®°å¿†åŠ å·¥")
        return {"content": content, "importance": 0.5}
    
    try:
        import aiohttp
        import re
        
        # æ ¹æ®è§’è‰²è®¾ç½®ä¸åŒçš„æç¤º
        if role == "user":
            role_hint = "ã€ä¸»äººè¯´ã€‘"
        else:
            role_hint = "ã€è‚¥ç‰›è¯´ã€‘"
        
        # æ„å»ºè®°å¿†åŠ å·¥ promptï¼ˆè‡ªç„¶è¯­è¨€æ ¼å¼ï¼‰
        prompt = f"""ä»å¯¹è¯ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œç”¨è‡ªç„¶æµç•…çš„è¯­è¨€è®°å½•ã€‚

èº«ä»½è¯´æ˜ï¼š
- "ä¸»äºº"æ˜¯ä½¿ç”¨AIçš„çœŸäººç”¨æˆ·
- "è‚¥ç‰›"æ˜¯AIåŠ©æ‰‹ï¼ˆä¸æ˜¯çœŸäººï¼‰

{role_hint}
{content}

æå–è§„åˆ™ï¼š
1. ç”¨è‡ªç„¶çš„ä¸­æ–‡æè¿°ï¼Œåƒå†™æ—¥è®°ä¸€æ ·
2. ç¤ºä¾‹ï¼š"ä¸»äººå–œæ¬¢åœ¨æ™šä¸ŠèŠå¤©ï¼›è¯´è‡ªå·±æœ€è¿‘å·¥ä½œå¾ˆå¿™"
3. å¤šä¸ªè¦ç‚¹ç”¨åˆ†å·è¿æ¥ï¼Œä¿ç•™å…³é”®ç»†èŠ‚
4. å¿½ç•¥æ— æ„ä¹‰çš„é—²èŠ

é‡è¦åº¦ï¼ˆ0.1-1.0ï¼‰ï¼š
- 0.9-1.0: æé‡è¦ï¼ˆç”Ÿæ—¥ã€æ ¸å¿ƒåå¥½ï¼‰
- 0.7-0.8: é‡è¦ï¼ˆä¹ æƒ¯ã€æ˜ç¡®è¡¨æ€ï¼‰
- 0.5-0.6: ä¸€èˆ¬ï¼ˆæ™®é€šè¯é¢˜ï¼‰
- 0.3ä»¥ä¸‹: å¯å¿½ç•¥

è¯·ç”¨JSONå›å¤ï¼š{{"memory": "è‡ªç„¶è¯­è¨€è®°å¿†", "importance": æ•°å€¼}}"""
        
        # è°ƒç”¨ LLM API
        async with aiohttp.ClientSession() as session:
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 2000,
                "temperature": 0.2
            }
            
            async with session.post(
                f"{base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    response_text = result['choices'][0]['message']['content'].strip()
                    
                    # å°è¯•è§£æ JSON
                    try:
                        # æå– JSON éƒ¨åˆ†ï¼ˆå¤„ç†å¯èƒ½çš„é¢å¤–æ–‡æœ¬ï¼‰
                        json_match = re.search(r'\{[^}]+\}', response_text)
                        if json_match:
                            parsed = json.loads(json_match.group())
                            memory_content = parsed.get('memory', content)
                            try:
                                importance = float(parsed.get('importance', 0.5))
                            except:
                                importance = 0.5
                            # ç¡®ä¿é‡è¦åº¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
                            importance = max(0.1, min(1.0, importance))
                            
                            print(f"ğŸ”§ è®°å¿†åŠ å·¥: {content[:30]}... â†’ {memory_content[:50]}... (é‡è¦åº¦: {importance})")
                            return {"content": memory_content, "importance": importance}
                        else:
                            # JSONåŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å“åº”
                            print(f"âš ï¸ æœªæ‰¾åˆ°JSONæ ¼å¼ï¼Œä½¿ç”¨åŸå§‹å“åº”")
                            return {"content": response_text, "importance": 0.5}
                    except (json.JSONDecodeError, ValueError) as e:
                        print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹å“åº”")
                        return {"content": response_text, "importance": 0.5}
                else:
                    error_text = await response.text()
                    print(f"âš ï¸ LLM åŠ å·¥å¤±è´¥ (status: {response.status}): {error_text[:200]}")
                    return {"content": content, "importance": 0.5}
    except aiohttp.ClientError as e:
        print(f"âš ï¸ ç½‘ç»œè¯·æ±‚å¤±è´¥: {type(e).__name__}: {e}")
        return {"content": content, "importance": 0.5}
    except Exception as e:
        print(f"âš ï¸ è®°å¿†åŠ å·¥å‡ºé”™: {type(e).__name__}: {e}")
        return {"content": content, "importance": 0.5}


async def process_conversation_batch(conversation: str) -> Dict[str, Any]:
    """
    ğŸ”¥ æ‰¹é‡å¯¹è¯åŠ å·¥ï¼šä»ä¸€æ®µå®Œæ•´å¯¹è¯ä¸­æå–å¤šæ¡å…³é”®è®°å¿†
    æ”¯æŒé‡è¯•æœºåˆ¶å’Œå¤‡ç”¨æ¨¡å‹
    
    è¿”å›æ ¼å¼:
    {
        "memories": [
            {"content": "è®°å¿†1å†…å®¹", "importance": 0.8},
            {"content": "è®°å¿†2å†…å®¹", "importance": 0.6},
            ...
        ]
    }
    """
    global llm_config, full_config
    
    if not llm_config:
        print("âš ï¸ LLM æœªé…ç½®ï¼Œæ— æ³•åŠ å·¥è®°å¿†")
        return {"memories": []}
    
    # æ„å»ºæ¨¡å‹åˆ—è¡¨ï¼šä¸»æ¨¡å‹ + å¤‡ç”¨æ¨¡å‹
    models_to_try = []
    
    # ä¸»æ¨¡å‹
    api_key = llm_config.get('api_key', '')
    model = llm_config.get('model', '')
    base_url = llm_config.get('base_url', '')
    
    if api_key and model and base_url:
        models_to_try.append({
            'name': 'ä¸»æ¨¡å‹',
            'api_key': api_key,
            'model': model,
            'base_url': base_url
        })
    
    # å¤‡ç”¨æ¨¡å‹
    fallback_config = full_config.get('llm_fallback', {}) if full_config else {}
    if fallback_config.get('enabled', False):
        fb_cfg = fallback_config.get('config', {})
        fb_api_key = fb_cfg.get('api_key', '')
        fb_model = fb_cfg.get('model', '')
        fb_base_url = fb_cfg.get('base_url', '')
        if fb_api_key and fb_model and fb_base_url:
            models_to_try.append({
                'name': 'å¤‡ç”¨æ¨¡å‹',
                'api_key': fb_api_key,
                'model': fb_model,
                'base_url': fb_base_url
            })
    
    if not models_to_try:
        print(f"âš ï¸ LLM é…ç½®ä¸å®Œæ•´ï¼Œæ— å¯ç”¨æ¨¡å‹")
        return {"memories": []}
    
    import aiohttp
    import re
    
    # æ„å»ºæ‰¹é‡è®°å¿†æå– prompt
    prompt = f"""ä½ æ˜¯è®°å¿†æå–ä¸“å®¶ã€‚ä»ä»¥ä¸‹å¤šè½®å¯¹è¯ä¸­æå–å…³é”®äº‹å®ï¼Œç”¨è‡ªç„¶æµç•…çš„è¯­è¨€è®°å½•ã€‚

èº«ä»½è¯´æ˜ï¼š
- "ä¸»äºº"æ˜¯ä½¿ç”¨AIçš„çœŸäººç”¨æˆ·
- "è‚¥ç‰›"æ˜¯AIåŠ©æ‰‹ï¼ˆä¸æ˜¯çœŸäººï¼‰

æå–è§„åˆ™ï¼š
1. ç”¨è‡ªç„¶çš„ä¸­æ–‡æè¿°ï¼Œåƒå†™æ—¥è®°ä¸€æ ·è®°å½•è¦ç‚¹
2. ç¤ºä¾‹æ ¼å¼ï¼š
   - "ä¸»äººå¸¸åœ¨æ™šä¸Šä¸AIäº’åŠ¨ï¼Œç§°å‘¼AIä¸ºè‚¥ç‰›ï¼›å–œæ¬¢å¬AIå”±æ­Œ"
   - "ä¸»äººè¯´è‡ªå·±ç”Ÿæ—¥æ˜¯5æœˆ20æ—¥ï¼Œå¸Œæœ›AIè®°ä½"
   - "ä¸»äººæœ€è¿‘åœ¨å­¦Pythonï¼Œé—®äº†å¾ˆå¤šç¼–ç¨‹é—®é¢˜"
   - "AIæ‰¿è¯ºå¸®ä¸»äººæé†’æ˜å¤©çš„ä¼šè®®"
3. å¤šä¸ªè¦ç‚¹å¯ä»¥ç”¨åˆ†å·æˆ–é€—å·è¿æ¥
4. æ¯æ¡è®°å¿†15-80å­—ï¼Œä¿ç•™å…³é”®ç»†èŠ‚
5. å¿½ç•¥æ— æ„ä¹‰çš„é—²èŠï¼ˆå¦‚"å—¯"ã€"å¥½çš„"ã€"çŸ¥é“äº†"ï¼‰
6. åˆ¤æ–­è®°å¿†é‡è¦æ€§ï¼ˆ0.1-1.0ï¼‰ï¼š
   - 0.9-1.0ï¼šæé‡è¦ï¼ˆç”Ÿæ—¥ã€é‡å¤§äº‹ä»¶ã€æ ¸å¿ƒåå¥½ï¼‰
   - 0.7-0.8ï¼šé‡è¦ï¼ˆä¹ æƒ¯ã€ç»å†ã€æ˜ç¡®è¡¨æ€ï¼‰
   - 0.5-0.6ï¼šä¸€èˆ¬ï¼ˆæ™®é€šè¯é¢˜ã€ä¸´æ—¶æƒ³æ³•ï¼‰
   - 0.3-0.4ï¼šè¾ƒä½ï¼ˆé—²èŠã€æ— å®è´¨å†…å®¹ï¼‰
7. å¯ä»¥æå–0-5æ¡è®°å¿†ï¼Œæ²¡æœ‰é‡è¦ä¿¡æ¯å°±è¿”å›ç©ºæ•°ç»„

å¯¹è¯å†…å®¹ï¼š
{conversation}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
```json
{{
    "memories": [
        {{"content": "æå–çš„è®°å¿†1", "importance": 0.8}},
        {{"content": "æå–çš„è®°å¿†2", "importance": 0.6}}
    ]
}}
```

å¦‚æœå¯¹è¯ä¸­æ²¡æœ‰å€¼å¾—è®°å¿†çš„ä¿¡æ¯ï¼Œè¿”å›ï¼š
```json
{{"memories": []}}
```
"""
    
    # é‡è¯•é…ç½®ï¼šæ¯ä¸ªæ¨¡å‹æœ€å¤šé‡è¯•2æ¬¡ï¼Œè¶…æ—¶æ—¶é—´é€’å¢
    timeouts = [60, 120]  # ç¬¬1æ¬¡60ç§’ï¼Œç¬¬2æ¬¡120ç§’
    last_error = None
    
    for model_info in models_to_try:
        model_name = model_info['name']
        current_model = model_info['model']
        current_api_key = model_info['api_key']
        current_base_url = model_info['base_url']
        
        for attempt, timeout_seconds in enumerate(timeouts, 1):
            try:
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨ LLM ({model_name}) åŠ å·¥è®°å¿†... (model: {current_model}, ç¬¬{attempt}æ¬¡, è¶…æ—¶{timeout_seconds}ç§’)")
                
                async with aiohttp.ClientSession() as session:
                    headers = {
                        "Authorization": f"Bearer {current_api_key}",
                        "Content-Type": "application/json"
                    }
                    
                    payload = {
                        "model": current_model,
                        "messages": [{"role": "user", "content": prompt}],
                        "max_tokens": 2000,
                        "temperature": 0.3
                    }
                    
                    # æŸäº›APIä¸æ”¯æŒ response_formatï¼Œå°è¯•æ·»åŠ 
                    try:
                        payload["response_format"] = {"type": "json_object"}
                    except:
                        pass
                    
                    async with session.post(
                        f"{current_base_url}/chat/completions",
                        headers=headers,
                        json=payload,
                        timeout=aiohttp.ClientTimeout(total=timeout_seconds)
                    ) as response:
                        if response.status == 200:
                            result = await response.json()
                            response_text = result['choices'][0]['message']['content'].strip()
                            
                            print(f"ğŸ“¥ LLM è¿”å›: {response_text[:200]}...")
                            
                            try:
                                # å°è¯•ç›´æ¥è§£æ
                                parsed = json.loads(response_text)
                            except json.JSONDecodeError:
                                # å°è¯•ä»è¿”å›æ–‡æœ¬ä¸­æå– JSON
                                json_match = re.search(r'\{[\s\S]*"memories"[\s\S]*\}', response_text)
                                if json_match:
                                    try:
                                        parsed = json.loads(json_match.group())
                                    except:
                                        print(f"âš ï¸ æ— æ³•è§£æJSONï¼Œè·³è¿‡è®°å¿†æå–")
                                        continue  # ç»§ç»­å°è¯•
                                else:
                                    print(f"âš ï¸ è¿”å›å†…å®¹ä¸åŒ…å«æœ‰æ•ˆJSON")
                                    continue  # ç»§ç»­å°è¯•
                            
                            memories = parsed.get('memories', [])
                            
                            # éªŒè¯å’Œæ¸…ç†
                            valid_memories = []
                            for mem in memories:
                                if isinstance(mem, dict) and mem.get('content'):
                                    content = str(mem['content']).strip()
                                    try:
                                        importance = float(mem.get('importance', 0.5))
                                    except:
                                        importance = 0.5
                                    importance = max(0.1, min(1.0, importance))
                                    if len(content) >= 5:
                                        valid_memories.append({
                                            "content": content,
                                            "importance": importance
                                        })
                            
                            print(f"ğŸ§  ä»å¯¹è¯ä¸­æå–äº† {len(valid_memories)} æ¡è®°å¿† ({model_name})")
                            for mem in valid_memories:
                                print(f"   - [{mem['importance']:.1f}] {mem['content'][:40]}...")
                            
                            return {"memories": valid_memories}
                        else:
                            error_text = await response.text()
                            last_error = f"status {response.status}: {error_text[:200]}"
                            print(f"âš ï¸ LLM è¯·æ±‚å¤±è´¥ ({model_name}, ç¬¬{attempt}æ¬¡): {last_error}")
                            continue  # ç»§ç»­å°è¯•
                            
            except asyncio.TimeoutError:
                last_error = f"è¶…æ—¶({timeout_seconds}ç§’)"
                print(f"âš ï¸ LLM è¶…æ—¶ ({model_name}, ç¬¬{attempt}æ¬¡, {timeout_seconds}ç§’)")
                continue  # ç»§ç»­å°è¯•
            except aiohttp.ClientError as e:
                last_error = f"{type(e).__name__}: {e}"
                print(f"âš ï¸ ç½‘ç»œè¯·æ±‚å¤±è´¥ ({model_name}, ç¬¬{attempt}æ¬¡): {last_error}")
                continue  # ç»§ç»­å°è¯•
            except Exception as e:
                last_error = f"{type(e).__name__}: {e}"
                print(f"âš ï¸ æœªçŸ¥é”™è¯¯ ({model_name}, ç¬¬{attempt}æ¬¡): {last_error}")
                continue  # ç»§ç»­å°è¯•
        
        # å½“å‰æ¨¡å‹æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
        print(f"âš ï¸ {model_name} æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹...")
    
    # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
    print(f"âŒ æ‰€æœ‰æ¨¡å‹å‡å¤±è´¥ï¼Œæœ€åé”™è¯¯: {last_error}")
    return {"memories": []}


@app.get("/")
async def root():
    return {
        "service": "MemOS API for è‚¥ç‰›AI",
        "version": "1.0.0",
        "status": "running",
        "user_id": USER_ID
    }


@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "model_loaded": embedding_model is not None,
        "memory_count": len(memory_store)
    }


@app.post("/add")
async def add_memory(request: AddMemoryRequest):
    """æ·»åŠ æ–°è®°å¿†ï¼ˆæ‰¹é‡å¯¹è¯åˆå¹¶åç»Ÿä¸€åŠ å·¥ï¼‰
    
    ğŸ”¥ æ ¸å¿ƒé€»è¾‘ï¼š
    1. å°†å¤šè½®å¯¹è¯åˆå¹¶æˆä¸€æ®µå®Œæ•´æ–‡æœ¬
    2. åªè°ƒç”¨ä¸€æ¬¡ LLM ä»ä¸­æå–å…³é”®è®°å¿†
    3. æ”¯æŒæå–å¤šæ¡è®°å¿†ï¼ˆç”¨åˆ†å·åˆ†éš”ï¼‰
    """
    global memory_store
    
    if not embedding_model:
        raise HTTPException(status_code=500, detail="Embedding æ¨¡å‹æœªåŠ è½½")
    
    try:
        added_count = 0
        merged_count = 0
        skipped_count = 0
        
        # ğŸ”¥ æ­¥éª¤1ï¼šå°†æ‰€æœ‰å¯¹è¯åˆå¹¶æˆä¸€æ®µæ–‡æœ¬
        conversation_text = []
        for msg in request.messages:
            content = msg.get('content', '')
            role = msg.get('role', 'user')
            if content and len(content.strip()) > 0:
                role_label = "ä¸»äºº" if role == 'user' else "è‚¥ç‰›"
                conversation_text.append(f"ã€{role_label}ã€‘{content}")
        
        if not conversation_text:
            return {"status": "success", "message": "æ— æœ‰æ•ˆå¯¹è¯", "added": 0, "merged": 0}
        
        full_conversation = "\n".join(conversation_text)
        print(f"ğŸ“ æ”¶åˆ° {len(request.messages)} æ¡æ¶ˆæ¯ï¼Œåˆå¹¶åå¼€å§‹åŠ å·¥...")
        
        # ğŸ”¥ æ­¥éª¤2ï¼šä¸€æ¬¡æ€§è°ƒç”¨ LLM æå–å…³é”®è®°å¿†
        processed_result = await process_conversation_batch(full_conversation)
        
        if not processed_result or not processed_result.get("memories"):
            print("âš ï¸ æœªæå–åˆ°æœ‰æ•ˆè®°å¿†")
            return {"status": "success", "message": "æœªæå–åˆ°æœ‰æ•ˆè®°å¿†", "added": 0, "merged": 0}
        
        # ğŸ”¥ æ­¥éª¤3ï¼šå¤„ç†æå–å‡ºçš„æ¯æ¡è®°å¿†
        for mem_item in processed_result["memories"]:
            content = mem_item.get("content", "").strip()
            importance = mem_item.get("importance", 0.5)
            
            if not content or len(content) < 5:
                continue
            
            # å¦‚æœé‡è¦åº¦å¤ªä½ï¼Œè·³è¿‡
            if importance < 0.3:
                print(f"â­ï¸ è·³è¿‡ä½é‡è¦åº¦è®°å¿† ({importance}): {content[:30]}...")
                skipped_count += 1
                continue
            
            # ç”Ÿæˆ embedding
            embedding = embedding_model.encode([content])[0].tolist()
            
            # å»é‡ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼è®°å¿†
            similar = find_similar_memory(embedding, threshold=0.95)
            
            if similar:
                idx, existing_mem, similarity = similar
                print(f"ğŸ” å‘ç°ç›¸ä¼¼è®°å¿† (ç›¸ä¼¼åº¦: {similarity:.2%})")
                
                # å°è¯•åˆå¹¶
                if await merge_memories(existing_mem, content, embedding):
                    merged_count += 1
                else:
                    # åˆå¹¶å¤±è´¥ï¼Œæ·»åŠ ä¸ºæ–°è®°å¿†
                    memory = {
                        "id": f"mem_{len(memory_store)}_{datetime.now().timestamp()}",
                        "content": content,
                        "timestamp": datetime.now().isoformat(),
                        "embedding": embedding,
                        "importance": importance,
                        "processed": True,
                        "merge_count": 0
                    }
                    memory_store.append(memory)
                    added_count += 1
            else:
                # æ²¡æœ‰ç›¸ä¼¼è®°å¿†ï¼Œæ·»åŠ æ–°è®°å¿†
                memory = {
                    "id": f"mem_{len(memory_store)}_{datetime.now().timestamp()}",
                    "content": content,
                    "timestamp": datetime.now().isoformat(),
                    "embedding": embedding,
                    "importance": importance,
                    "processed": True,
                    "merge_count": 0
                }
                memory_store.append(memory)
                added_count += 1
                print(f"âœ… æ–°å¢è®°å¿†: {content[:50]}... (é‡è¦åº¦: {importance})")
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        save_memory_store()
        
        # æ„å»ºè¿”å›æ¶ˆæ¯
        result_parts = []
        if added_count > 0:
            result_parts.append(f"æ–°å¢ {added_count} æ¡")
        if merged_count > 0:
            result_parts.append(f"åˆå¹¶ {merged_count} æ¡")
        if skipped_count > 0:
            result_parts.append(f"è·³è¿‡ {skipped_count} æ¡")
        
        result_msg = "è®°å¿†å·²å¤„ç†ï¼š" + "ã€".join(result_parts) if result_parts else "æ— æœ‰æ•ˆè®°å¿†"
        
        return {
            "status": "success",
            "message": result_msg,
            "added": added_count,
            "merged": merged_count,
            "skipped": skipped_count
        }
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æ·»åŠ è®°å¿†å¤±è´¥: {str(e)}")


@app.post("/add_raw")
async def add_memory_raw(request: AddRawMemoryRequest):
    """ç›´æ¥æ·»åŠ è®°å¿†ï¼ˆä¸ç»è¿‡ LLM åŠ å·¥ï¼‰"""
    global memory_store
    
    if not embedding_model:
        raise HTTPException(status_code=500, detail="Embedding æ¨¡å‹æœªåŠ è½½")
    
    try:
        added_count = 0
        
        for msg in request.messages:
            content = msg.content
            importance = msg.importance if msg.importance is not None else 0.8
            
            if content and len(content) > 5:
                # ç›´æ¥ä½¿ç”¨åŸå†…å®¹ï¼Œä¸åŠ å·¥
                embedding = embedding_model.encode([content])[0].tolist()
                
                # æ£€æŸ¥å»é‡
                similar = find_similar_memory(embedding, threshold=0.95)
                
                if similar:
                    idx, existing_mem, similarity = similar
                    print(f"ğŸ” å‘ç°ç›¸ä¼¼è®°å¿†ï¼Œè·³è¿‡æ·»åŠ  (ç›¸ä¼¼åº¦: {similarity:.2%})")
                    continue
                
                # æ·»åŠ æ–°è®°å¿†
                memory = {
                    "id": f"mem_{len(memory_store)}_{datetime.now().timestamp()}",
                    "content": content,
                    "role": msg.role or 'user',
                    "timestamp": datetime.now().isoformat(),
                    "created_at": datetime.now().isoformat(),
                    "embedding": embedding,
                    "importance": importance,
                    "processed": False,  # æ ‡è®°æœªåŠ å·¥
                    "merge_count": 0
                }
                
                memory_store.append(memory)
                added_count += 1
                print(f"âœ… ç›´æ¥æ·»åŠ è®°å¿†: {content[:50]}...")
        
        save_memory_store()
        
        return {
            "status": "success",
            "message": f"ç›´æ¥æ·»åŠ  {added_count} æ¡è®°å¿†",
            "added": added_count
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ·»åŠ å¤±è´¥: {str(e)}")


@app.put("/update/{memory_id}")
async def update_memory(memory_id: str, content: str, importance: Optional[float] = None):
    """æ›´æ–°è®°å¿†å†…å®¹"""
    global memory_store
    
    if not embedding_model:
        raise HTTPException(status_code=500, detail="Embedding æ¨¡å‹æœªåŠ è½½")
    
    try:
        # æŸ¥æ‰¾è®°å¿†
        mem = next((m for m in memory_store if m['id'] == memory_id), None)
        
        if not mem:
            raise HTTPException(status_code=404, detail=f"è®°å¿† {memory_id} ä¸å­˜åœ¨")
        
        # æ›´æ–°å†…å®¹
        mem['content'] = content
        mem['timestamp'] = datetime.now().isoformat()
        
        if importance is not None:
            mem['importance'] = importance
        
        # é‡æ–°ç”Ÿæˆ embedding
        mem['embedding'] = embedding_model.encode([content])[0].tolist()
        
        save_memory_store()
        
        print(f"âœ… è®°å¿†å·²æ›´æ–°: {memory_id}")
        
        return {"status": "success", "message": "è®°å¿†å·²æ›´æ–°"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±è´¥: {str(e)}")


@app.post("/search")
async def search_memory(request: SearchMemoryRequest):
    """æœç´¢ç›¸å…³è®°å¿†ï¼ˆç»¼åˆè€ƒè™‘ç›¸ä¼¼åº¦å’Œé‡è¦åº¦ï¼‰"""
    global memory_store
    
    if not embedding_model:
        raise HTTPException(status_code=500, detail="Embedding æ¨¡å‹æœªåŠ è½½")
    
    if len(memory_store) == 0:
        return {"query": request.query, "memories": [], "count": 0}
    
    try:
        # ç”ŸæˆæŸ¥è¯¢ embedding
        query_embedding = embedding_model.encode([request.query])[0]
        
        # ğŸ”¥ é‡è¦åº¦åŠ æƒå› å­ï¼ˆå¯è°ƒæ•´ï¼‰
        # 0.0 = å®Œå…¨ä¸è€ƒè™‘é‡è¦åº¦ï¼Œåªçœ‹ç›¸ä¼¼åº¦
        # 0.3 = é‡è¦åº¦æœ‰ä¸€å®šå½±å“ï¼ˆæ¨èï¼‰
        # 0.5 = é‡è¦åº¦å½±å“è¾ƒå¤§
        IMPORTANCE_WEIGHT = 0.3
        
        # è®¡ç®—ç›¸ä¼¼åº¦å’Œç»¼åˆå¾—åˆ†
        scored_memories = []
        for mem in memory_store:
            mem_embedding = np.array(mem['embedding'])
            similarity = float(cosine_similarity([query_embedding], [mem_embedding])[0][0])
            importance = mem.get('importance', 0.5)
            
            # ğŸ”¥ ç»¼åˆå¾—åˆ† = ç›¸ä¼¼åº¦ * (1 + é‡è¦åº¦ * åŠ æƒå› å­)
            # ä¾‹å¦‚ï¼šç›¸ä¼¼åº¦0.8ï¼Œé‡è¦åº¦0.9 â†’ 0.8 * (1 + 0.9 * 0.3) = 0.8 * 1.27 = 1.016
            # ä¾‹å¦‚ï¼šç›¸ä¼¼åº¦0.8ï¼Œé‡è¦åº¦0.3 â†’ 0.8 * (1 + 0.3 * 0.3) = 0.8 * 1.09 = 0.872
            final_score = similarity * (1 + importance * IMPORTANCE_WEIGHT)
            
            scored_memories.append((mem, similarity, final_score))
        
        # ğŸ”¥ æŒ‰ç»¼åˆå¾—åˆ†æ’åºï¼ˆä¸æ˜¯çº¯ç›¸ä¼¼åº¦ï¼‰
        scored_memories.sort(key=lambda x: x[2], reverse=True)
        
        # ğŸ”¥ åº”ç”¨ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤
        threshold = request.similarity_threshold or 0.5
        filtered_memories = [(mem, sim, score) for mem, sim, score in scored_memories if sim >= threshold]
        
        # å– top_k
        top_memories = filtered_memories[:request.top_k]
        
        # ğŸ”¥ è°ƒè¯•æ—¥å¿—
        print(f"ğŸ” æœç´¢ '{request.query[:30]}...': æ€»å…± {len(memory_store)} æ¡ï¼Œé«˜äºé˜ˆå€¼ {threshold} çš„æœ‰ {len(filtered_memories)} æ¡ï¼Œè¿”å› {len(top_memories)} æ¡")
        
        # æ ¼å¼åŒ–è¿”å›
        results = [
            {
                "content": mem['content'],
                "similarity": round(sim, 4),
                "importance": mem.get('importance', 0.5),
                "final_score": round(score, 4),  # è¿”å›ç»¼åˆå¾—åˆ†
                # ğŸ”¥ è¿”å›åˆ›å»ºæ—¶é—´ï¼ˆä¼˜å…ˆï¼‰å’Œæ›´æ–°æ—¶é—´
                "timestamp": mem.get('created_at') or mem.get('timestamp'),
                "created_at": mem.get('created_at') or mem.get('timestamp'),
                "updated_at": mem.get('updated_at')
            }
            for mem, sim, score in top_memories
        ]
        
        return {
            "query": request.query,
            "memories": results,
            "count": len(results)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœç´¢è®°å¿†å¤±è´¥: {str(e)}")


@app.get("/list")
async def list_memories(user_id: Optional[str] = USER_ID, limit: int = 100):
    """åˆ—å‡ºæ‰€æœ‰è®°å¿†"""
    global memory_store
    
    try:
        # è¿”å›æœ€è¿‘çš„è®°å¿†
        recent_memories = memory_store[-limit:] if len(memory_store) > limit else memory_store
        
        results = [
            {
                "id": mem['id'],
                "content": mem['content'],
                # ğŸ”¥ è¿”å›åˆ›å»ºæ—¶é—´å’Œæ›´æ–°æ—¶é—´
                "timestamp": mem.get('created_at') or mem.get('timestamp'),  # ä¼˜å…ˆè¿”å›åˆ›å»ºæ—¶é—´
                "created_at": mem.get('created_at') or mem.get('timestamp'),
                "updated_at": mem.get('updated_at'),
                "importance": mem.get('importance', 0.5),
                "merge_count": mem.get('merge_count', 0)  # æ˜¾ç¤ºåˆå¹¶æ¬¡æ•°
            }
            for mem in reversed(recent_memories)  # æœ€æ–°çš„åœ¨å‰
        ]
        
        return {
            "user_id": user_id,
            "count": len(results),
            "memories": results
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ—å‡ºè®°å¿†å¤±è´¥: {str(e)}")


@app.get("/check_similarity")
async def check_similarity(id1: str, id2: str):
    """æ£€æŸ¥ä¸¤æ¡è®°å¿†çš„ç›¸ä¼¼åº¦"""
    global memory_store
    
    try:
        mem1 = next((m for m in memory_store if m['id'] == id1), None)
        mem2 = next((m for m in memory_store if m['id'] == id2), None)
        
        if not mem1:
            raise HTTPException(status_code=404, detail=f"è®°å¿† {id1} ä¸å­˜åœ¨")
        if not mem2:
            raise HTTPException(status_code=404, detail=f"è®°å¿† {id2} ä¸å­˜åœ¨")
        
        emb1 = np.array(mem1['embedding'])
        emb2 = np.array(mem2['embedding'])
        
        similarity = float(cosine_similarity([emb1], [emb2])[0][0])
        
        return {
            "memory_1": {"id": id1, "content": mem1['content'][:100]},
            "memory_2": {"id": id2, "content": mem2['content'][:100]},
            "similarity": round(similarity * 100, 2),
            "would_merge_at_threshold": {
                "0.95": similarity >= 0.95,
                "0.90": similarity >= 0.90,
                "0.85": similarity >= 0.85,
                "0.80": similarity >= 0.80
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ£€æŸ¥å¤±è´¥: {str(e)}")


@app.delete("/delete/{memory_id}")
async def delete_memory(memory_id: str, user_id: Optional[str] = USER_ID):
    """åˆ é™¤æŒ‡å®šè®°å¿†"""
    global memory_store
    
    try:
        # æŸ¥æ‰¾å¹¶åˆ é™¤
        original_length = len(memory_store)
        memory_store = [mem for mem in memory_store if mem['id'] != memory_id]
        
        if len(memory_store) < original_length:
            save_memory_store()
            return {"status": "success", "message": f"è®°å¿† {memory_id} å·²åˆ é™¤"}
        else:
            raise HTTPException(status_code=404, detail=f"è®°å¿† {memory_id} ä¸å­˜åœ¨")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤è®°å¿†å¤±è´¥: {str(e)}")


def find_similar_memory(new_embedding, threshold=0.95):
    """æŸ¥æ‰¾ç›¸ä¼¼çš„è®°å¿†ï¼ˆç”¨äºå»é‡ï¼‰"""
    global memory_store
    
    if len(memory_store) == 0:
        return None
    
    new_emb = np.array(new_embedding)
    max_similarity = 0
    most_similar_idx = -1
    
    for idx, mem in enumerate(memory_store):
        mem_emb = np.array(mem['embedding'])
        similarity = cosine_similarity([new_emb], [mem_emb])[0][0]
        
        if similarity > max_similarity:
            max_similarity = similarity
            most_similar_idx = idx
    
    if max_similarity >= threshold:
        return most_similar_idx, memory_store[most_similar_idx], float(max_similarity)
    
    return None


async def merge_memories(existing_mem, new_content, new_embedding):
    """åˆå¹¶ä¸¤æ¡ç›¸ä¼¼çš„è®°å¿†ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
    global llm_config
    
    # æ£€æŸ¥ LLM é…ç½®
    if not llm_config:
        print("âš ï¸ LLM æœªé…ç½®ï¼Œæ— æ³•åˆå¹¶è®°å¿†")
        return False
    
    import aiohttp
    import asyncio
    
    # æ„å»ºåˆå¹¶ prompt
    prompt = f"""åˆå¹¶ä»¥ä¸‹ä¸¤æ¡ç›¸ä¼¼çš„è®°å¿†ï¼Œä¿ç•™æ‰€æœ‰æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼Œå»é™¤é‡å¤å†…å®¹ï¼š

å·²æœ‰è®°å¿†ï¼š{existing_mem['content']}
æ–°å¢ä¿¡æ¯ï¼š{new_content}

åˆå¹¶åçš„è®°å¿†ï¼ˆä¿ç•™æ‰€æœ‰ç»†èŠ‚ï¼Œç”¨åˆ†å·åˆ†éš”è¦ç‚¹ï¼‰ï¼š"""
    
    api_key = llm_config.get('api_key', '')
    model = llm_config.get('model', '')
    base_url = llm_config.get('base_url', '')
    
    if not all([api_key, model, base_url]):
        print("âš ï¸ LLM é…ç½®ä¸å®Œæ•´ï¼Œæ— æ³•åˆå¹¶è®°å¿†")
        return False
    
    # ğŸ”¥ é‡è¯•æœºåˆ¶ï¼šæœ€å¤š 3 æ¬¡ï¼Œè¶…æ—¶é€æ¬¡å¢åŠ 
    max_retries = 3
    timeouts = [60, 90, 120]  # ç¬¬1æ¬¡60ç§’ï¼Œç¬¬2æ¬¡90ç§’ï¼Œç¬¬3æ¬¡120ç§’
    
    for attempt in range(max_retries):
        try:
            timeout_seconds = timeouts[attempt]
            
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 2000,
                    "temperature": 0.2
                }
                
                async with session.post(
                    f"{base_url}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=timeout_seconds)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        merged = result['choices'][0]['message']['content'].strip()
                        
                        # ğŸ”¥ ä¿ç•™æœ€æ—©çš„æ—¶é—´ä½œä¸º created_at
                        if 'created_at' not in existing_mem:
                            existing_mem['created_at'] = existing_mem.get('timestamp', datetime.now().isoformat())
                        
                        # æ›´æ–°è®°å¿†
                        existing_mem['content'] = merged
                        # ğŸ”¥ ç¡®ä¿ embedding æ˜¯ list ç±»å‹ï¼ˆä¸æ˜¯ numpy ndarrayï¼‰
                        if hasattr(new_embedding, 'tolist'):
                            existing_mem['embedding'] = new_embedding.tolist()
                        else:
                            existing_mem['embedding'] = list(new_embedding) if new_embedding else []
                        existing_mem['updated_at'] = datetime.now().isoformat()
                        existing_mem['merge_count'] = existing_mem.get('merge_count', 0) + 1
                        
                        print(f"ğŸ”— è®°å¿†å·²åˆå¹¶ (ç¬¬ {existing_mem['merge_count']} æ¬¡): {merged[:50]}...")
                        return True
                    else:
                        error_text = await response.text()
                        print(f"âš ï¸ LLM API è¿”å›é”™è¯¯ {response.status}: {error_text[:200]}")
                        return False  # API é”™è¯¯ä¸é‡è¯•
                        
        except asyncio.TimeoutError:
            print(f"âš ï¸ ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•è¶…æ—¶ ({timeout_seconds}ç§’)")
            if attempt < max_retries - 1:
                print(f"   ğŸ”„ ç­‰å¾… 2 ç§’åé‡è¯•...")
                await asyncio.sleep(2)
            continue
        except Exception as e:
            import traceback
            print(f"âš ï¸ åˆå¹¶å¤±è´¥: {e}")
            traceback.print_exc()
            return False
    
    print(f"âš ï¸ æ‰€æœ‰é‡è¯•å‡å¤±è´¥")
    return False


class NumpyEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰ JSON ç¼–ç å™¨ï¼Œå¤„ç† numpy ç±»å‹"""
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        if isinstance(obj, (np.float32, np.float64)):
            return float(obj)
        if isinstance(obj, (np.int32, np.int64)):
            return int(obj)
        return super().default(obj)


def save_memory_store():
    """ä¿å­˜è®°å¿†åˆ°æ–‡ä»¶ï¼ˆåŸå­å†™å…¥ï¼Œé˜²æ­¢æŸåï¼‰"""
    try:
        data_dir = os.path.join(os.path.dirname(__file__), "..", "data")
        os.makedirs(data_dir, exist_ok=True)
        memory_file = os.path.join(data_dir, "memory_store.json")
        temp_file = memory_file + ".tmp"
        
        # ğŸ”¥ å…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼ˆä½¿ç”¨è‡ªå®šä¹‰ç¼–ç å™¨å¤„ç† numpy ç±»å‹ï¼‰
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(memory_store, f, ensure_ascii=False, indent=2, cls=NumpyEncoder)
        
        # ğŸ”¥ éªŒè¯ä¸´æ—¶æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        with open(temp_file, 'r', encoding='utf-8') as f:
            json.load(f)  # å°è¯•è§£æï¼Œç¡®ä¿ JSON æœ‰æ•ˆ
        
        # ğŸ”¥ åŸå­æ›¿æ¢ï¼šåˆ é™¤æ—§æ–‡ä»¶ï¼Œé‡å‘½åä¸´æ—¶æ–‡ä»¶
        if os.path.exists(memory_file):
            os.remove(memory_file)
        os.rename(temp_file, memory_file)
        
    except Exception as e:
        print(f"ä¿å­˜è®°å¿†å¤±è´¥: {e}")
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        temp_file = os.path.join(os.path.dirname(__file__), "..", "data", "memory_store.json.tmp")
        if os.path.exists(temp_file):
            os.remove(temp_file)


@app.post("/migrate")
async def migrate_from_txt(request: MigrateRequest):
    """ä»æ—§è®°å¿†åº“.txt æ–‡ä»¶å¯¼å…¥è®°å¿†"""
    global memory_store
    
    if not embedding_model:
        raise HTTPException(status_code=500, detail="Embedding æ¨¡å‹æœªåŠ è½½")
    
    try:
        file_path = request.file_path
        
        # å°è¯•ç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
        if not os.path.isabs(file_path):
            file_path = os.path.join(os.getcwd(), file_path)
        
        if not os.path.exists(file_path):
            # å°è¯• live-2d ç›®å½•
            alt_path = os.path.join("live-2d", request.file_path)
            if os.path.exists(alt_path):
                file_path = alt_path
            else:
                raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ä¸å­˜åœ¨: {request.file_path}")
        
        print(f"ğŸ“‚ è¯»å–æ–‡ä»¶: {file_path}")
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŒ‰åˆ†éš”çº¿åˆ†å‰²å†…å®¹
        separator_pattern = r'\s*-{10,}\s*'
        sections = re.split(separator_pattern, content)
        
        imported_count = 0
        for section in sections:
            section = section.strip()
            if section and len(section) > 10:
                # ç”Ÿæˆ embedding
                embedding = embedding_model.encode([section])[0].tolist()
                
                # åˆ›å»ºè®°å¿†å¯¹è±¡
                memory = {
                    "id": f"migrated_{imported_count}_{datetime.now().timestamp()}",
                    "content": section,
                    "role": "user",
                    "timestamp": datetime.now().isoformat(),
                    "embedding": embedding,
                    "importance": 0.7,
                    "source": "migrated"
                }
                
                memory_store.append(memory)
                imported_count += 1
        
        # ä¿å­˜
        save_memory_store()
        
        print(f"âœ… æˆåŠŸå¯¼å…¥ {imported_count} æ¡è®°å¿†")
        
        return {
            "status": "success",
            "imported_count": imported_count,
            "message": f"æˆåŠŸå¯¼å…¥ {imported_count} æ¡è®°å¿†"
        }
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å¯¼å…¥è®°å¿†å¤±è´¥: {str(e)}")


@app.post("/reprocess")
async def reprocess_all_memories():
    """æ‰¹é‡åŠ å·¥æ‰€æœ‰æœªå¤„ç†çš„è®°å¿†"""
    global memory_store
    
    if not embedding_model or not llm_config:
        raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½")
    
    try:
        processed_count = 0
        failed_count = 0
        
        print("ğŸ”§ å¼€å§‹æ‰¹é‡åŠ å·¥è®°å¿†...")
        
        for i, mem in enumerate(memory_store):
            # è·³è¿‡å·²åŠ å·¥çš„è®°å¿†
            if mem.get('processed'):
                continue
            
            original_content = mem.get('content', '')
            if len(original_content) < 10:
                continue
            
            # è·å–è®°å¿†çš„è§’è‰²ï¼ˆé»˜è®¤ä¸º userï¼‰
            mem_role = mem.get('role', 'user')
            print(f"å¤„ç† {i+1}/{len(memory_store)} [{mem_role}]: {original_content[:50]}...")
            
            try:
                # ä½¿ç”¨ LLM åŠ å·¥ï¼ˆè¿”å›å†…å®¹å’Œé‡è¦åº¦ï¼‰
                processed_result = await process_memory_with_llm(original_content, mem_role)
                processed_content = processed_result["content"]
                importance = processed_result["importance"]
                
                # æ›´æ–°è®°å¿†
                mem['original_content'] = original_content
                mem['content'] = processed_content
                mem['importance'] = importance  # æ›´æ–°é‡è¦åº¦
                mem['processed'] = True
                
                # é‡æ–°ç”Ÿæˆ embeddingï¼ˆä½¿ç”¨åŠ å·¥åçš„å†…å®¹ï¼‰
                new_embedding = embedding_model.encode([processed_content])[0].tolist()
                mem['embedding'] = new_embedding
                
                processed_count += 1
                print(f"  âœ… é‡è¦åº¦: {importance}")
                
                # æ¯å¤„ç† 10 æ¡ä¿å­˜ä¸€æ¬¡
                if processed_count % 10 == 0:
                    save_memory_store()
                    print(f"  âœ… å·²å¤„ç† {processed_count} æ¡")
                
            except Exception as e:
                print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
                failed_count += 1
        
        # æœ€ç»ˆä¿å­˜
        save_memory_store()
        
        print(f"âœ… æ‰¹é‡åŠ å·¥å®Œæˆï¼æˆåŠŸ: {processed_count}, å¤±è´¥: {failed_count}")
        
        return {
            "status": "success",
            "processed_count": processed_count,
            "failed_count": failed_count,
            "message": f"æˆåŠŸåŠ å·¥ {processed_count} æ¡è®°å¿†"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡åŠ å·¥å¤±è´¥: {str(e)}")


@app.post("/deduplicate")
async def deduplicate_all_memories(threshold: float = 0.90):
    """å…¨å±€å»é‡åˆå¹¶ï¼šæ‰«ææ‰€æœ‰è®°å¿†ï¼Œåˆå¹¶é«˜åº¦ç›¸ä¼¼çš„è®°å¿†
    
    å‚æ•°:
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œ0.90 è¡¨ç¤º 90% ç›¸ä¼¼åˆ™åˆå¹¶
    """
    global memory_store
    
    if not embedding_model:
        raise HTTPException(status_code=500, detail="Embedding æ¨¡å‹æœªåŠ è½½")
    
    if len(memory_store) < 2:
        return {"status": "success", "merged_count": 0, "merge_details": [], "message": "è®°å¿†å¤ªå°‘ï¼Œæ— éœ€å»é‡"}
    
    try:
        print(f"ğŸ” å¼€å§‹å…¨å±€å»é‡ï¼ˆé˜ˆå€¼: {threshold}ï¼‰...")
        
        # ğŸ”¥ æ£€æŸ¥ LLM é…ç½®çŠ¶æ€
        if llm_config:
            print(f"âœ… LLM é…ç½®å¯ç”¨: {llm_config.get('model', 'N/A')}")
        else:
            print(f"âš ï¸ LLM æœªé…ç½®ï¼Œå°†ä½¿ç”¨ç®€å•åˆå¹¶ç­–ç•¥")
        merged_count = 0
        deleted_ids = set()
        merge_details = []  # ğŸ”¥ è®°å½•åˆå¹¶è¯¦æƒ…
        
        # åŒé‡å¾ªç¯æ£€æŸ¥æ‰€æœ‰è®°å¿†å¯¹
        for i in range(len(memory_store)):
            if memory_store[i]['id'] in deleted_ids:
                continue
            
            mem_i = memory_store[i]
            emb_i = np.array(mem_i['embedding'])
            original_content_i = mem_i['content']  # ä¿å­˜åŸå§‹å†…å®¹
            
            for j in range(i + 1, len(memory_store)):
                if memory_store[j]['id'] in deleted_ids:
                    continue
                
                mem_j = memory_store[j]
                emb_j = np.array(mem_j['embedding'])
                
                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = float(cosine_similarity([emb_i], [emb_j])[0][0])
                
                if similarity >= threshold:
                    print(f"ğŸ”— å‘ç°ç›¸ä¼¼è®°å¿† (ç›¸ä¼¼åº¦: {similarity:.2%})")
                    print(f"   è®°å¿†1: {mem_i['content'][:50]}...")
                    print(f"   è®°å¿†2: {mem_j['content'][:50]}...")
                    
                    # ğŸ”¥ ç¡®å®šæ›´æ—©çš„æ—¶é—´ä½œä¸º created_at
                    time_i = mem_i.get('created_at') or mem_i.get('timestamp', '')
                    time_j = mem_j.get('created_at') or mem_j.get('timestamp', '')
                    earlier_time = min(time_i, time_j) if time_i and time_j else (time_i or time_j)
                    
                    # ä¿å­˜åˆå¹¶å‰çš„å†…å®¹
                    content_before_i = mem_i['content']
                    content_before_j = mem_j['content']
                    
                    # å°è¯•ç”¨ LLM åˆå¹¶
                    print(f"   ğŸ¤– æ­£åœ¨è°ƒç”¨ LLM åˆå¹¶...")
                    merge_success = await merge_memories(mem_i, mem_j['content'], emb_j)
                    print(f"   ğŸ¤– LLM åˆå¹¶ç»“æœ: {'æˆåŠŸ' if merge_success else 'å¤±è´¥'}")
                    
                    # ğŸ”¥ è®°å½•åˆå¹¶è¯¦æƒ…
                    detail = {
                        "similarity": round(similarity * 100, 1),
                        "memory_1": content_before_i[:100] + ("..." if len(content_before_i) > 100 else ""),
                        "memory_2": content_before_j[:100] + ("..." if len(content_before_j) > 100 else ""),
                        "result": mem_i['content'][:100] + ("..." if len(mem_i['content']) > 100 else ""),
                        "method": "LLMåˆå¹¶" if merge_success else "ä¿ç•™é«˜é‡è¦åº¦"
                    }
                    merge_details.append(detail)
                    
                    if merge_success:
                        # ä¿ç•™æ›´æ—©çš„æ—¶é—´
                        if earlier_time:
                            mem_i['created_at'] = earlier_time
                        # æ ‡è®° j ä¸ºåˆ é™¤
                        deleted_ids.add(mem_j['id'])
                        merged_count += 1
                        print(f"   âœ… å·²åˆå¹¶ï¼Œåˆ é™¤è®°å¿†2")
                    else:
                        # ğŸ”¥ åˆå¹¶å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸€å¯¹ï¼Œä¿ç•™ä¸¤æ¡è®°å¿†
                        print(f"   â­ï¸ LLMåˆå¹¶å¤±è´¥ï¼Œè·³è¿‡æ­¤å¯¹è®°å¿†ï¼ˆä¸¤æ¡å‡ä¿ç•™ï¼‰")
                        merge_details.pop()  # ç§»é™¤æœªå®Œæˆçš„åˆå¹¶è¯¦æƒ…
        
        # åˆ é™¤è¢«æ ‡è®°çš„è®°å¿†
        if deleted_ids:
            memory_store = [m for m in memory_store if m['id'] not in deleted_ids]
            save_memory_store()
        
        print(f"âœ… å»é‡å®Œæˆï¼åˆå¹¶ {merged_count} æ¡è®°å¿†")
        
        return {
            "status": "success",
            "merged_count": merged_count,
            "remaining_count": len(memory_store),
            "merge_details": merge_details,  # ğŸ”¥ è¿”å›åˆå¹¶è¯¦æƒ…
            "message": f"åˆå¹¶ {merged_count} æ¡ç›¸ä¼¼è®°å¿†ï¼Œå‰©ä½™ {len(memory_store)} æ¡"
        }
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å»é‡å¤±è´¥: {str(e)}")


@app.get("/stats")
async def get_statistics():
    """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
    global memory_store
    
    try:
        total_count = len(memory_store)
        
        # è®¡ç®—æœ¬å‘¨æ–°å¢
        from datetime import timedelta
        now = datetime.now()
        week_ago = now - timedelta(days=7)
        week_count = 0
        
        for mem in memory_store:
            try:
                mem_time = datetime.fromisoformat(mem.get('timestamp', ''))
                if mem_time >= week_ago:
                    week_count += 1
            except:
                pass
        
        # è®¡ç®—ä»Šå¤©æ–°å¢
        today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
        today_count = 0
        
        for mem in memory_store:
            try:
                mem_time = datetime.fromisoformat(mem.get('timestamp', ''))
                if mem_time >= today_start:
                    today_count += 1
            except:
                pass
        
        # è®¡ç®—å¹³å‡é‡è¦åº¦
        if total_count > 0:
            avg_importance = sum(mem.get('importance', 0.5) for mem in memory_store) / total_count
        else:
            avg_importance = 0
        
        return {
            "total_count": total_count,
            "today_count": today_count,
            "week_count": week_count,
            "avg_importance": round(avg_importance, 2),
            "storage_path": "./memos_data"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    print("=" * 60)
    print("  MemOS è®°å¿†æœåŠ¡ for è‚¥ç‰›AI")
    print("=" * 60)
    print("  ç«¯å£: 8003")
    print("  æ–‡æ¡£: http://127.0.0.1:8003/docs")
    print("=" * 60)
    
    uvicorn.run(app, host="0.0.0.0", port=8003)

