// llm-client.js - ç»Ÿä¸€çš„LLM APIå®¢æˆ·ç«¯
const { logToTerminal, handleAPIError } = require('../api-utils.js');

/**
 * ç»Ÿä¸€çš„LLMå®¢æˆ·ç«¯
 * å°è£…æ‰€æœ‰LLM APIè°ƒç”¨é€»è¾‘,æ¶ˆé™¤é‡å¤ä»£ç 
 */
class LLMClient {
    constructor(config) {
        this.apiKey = config.llm.api_key;
        this.apiUrl = config.llm.api_url;
        this.model = config.llm.model;
    }

    /**
     * å‘é€èŠå¤©å®Œæˆè¯·æ±‚
     * @param {Array} messages - æ¶ˆæ¯æ•°ç»„
     * @param {Array} tools - å¯é€‰çš„å·¥å…·åˆ—è¡¨
     * @param {boolean} stream - æ˜¯å¦ä½¿ç”¨æµå¼å“åº”
     * @returns {Promise<Object>} APIå“åº”çš„æ¶ˆæ¯å¯¹è±¡
     */
    async chatCompletion(messages, tools = null, stream = false) {
        const requestBody = {
            model: this.model,
            messages: messages,
            stream: stream
        };

        // æ·»åŠ å·¥å…·åˆ—è¡¨(å¦‚æœæä¾›)
        if (tools && tools.length > 0) {
            requestBody.tools = tools;
            logToTerminal('info', `ğŸ”§ å‘é€å·¥å…·åˆ—è¡¨åˆ°LLM: ${tools.length}ä¸ªå·¥å…·`);
        }

        logToTerminal('info', `å¼€å§‹å‘é€è¯·æ±‚åˆ°LLM API: ${this.apiUrl}/chat/completions`);

        try {
            const response = await fetch(`${this.apiUrl}/chat/completions`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${this.apiKey}`
                },
                body: JSON.stringify(requestBody)
            });

            if (!response.ok) {
                await handleAPIError(response);
            }

            const responseData = await response.json();

            // éªŒè¯å“åº”æ ¼å¼
            this._validateResponse(responseData);

            logToTerminal('info', `æ”¶åˆ°LLM APIå“åº”`);

            return responseData.choices[0].message;

        } catch (error) {
            logToTerminal('error', `LLM APIè°ƒç”¨å¤±è´¥: ${error.message}`);
            throw error;
        }
    }

    /**
     * éªŒè¯APIå“åº”æ ¼å¼
     * @private
     */
    _validateResponse(responseData) {
        // æ£€æŸ¥APIé”™è¯¯å“åº”
        if (responseData.error) {
            const errorMsg = responseData.error.message || responseData.error || 'æœªçŸ¥APIé”™è¯¯';
            logToTerminal('error', `LLM APIé”™è¯¯: ${errorMsg}`);
            throw new Error(`APIé”™è¯¯: ${errorMsg}`);
        }

        // æ£€æŸ¥å“åº”æ ¼å¼,é€‚åº”ä¸åŒçš„APIå“åº”ç»“æ„
        let choices;
        if (responseData.choices) {
            choices = responseData.choices;
        } else if (responseData.data && responseData.data.choices) {
            choices = responseData.data.choices;
        } else {
            logToTerminal('error', `LLMå“åº”æ ¼å¼å¼‚å¸¸: ${JSON.stringify(responseData)}`);
            throw new Error('LLMå“åº”æ ¼å¼å¼‚å¸¸ï¼šç¼ºå°‘choiceså­—æ®µæˆ–ä¸ºç©º');
        }

        if (!choices || choices.length === 0) {
            logToTerminal('error', `LLMå“åº”æ ¼å¼å¼‚å¸¸: choicesä¸ºç©º`);
            throw new Error('LLMå“åº”æ ¼å¼å¼‚å¸¸ï¼šchoicesä¸ºç©º');
        }

        // å°†æ ‡å‡†åŒ–çš„choiceså†™å›
        responseData.choices = choices;
    }

    /**
     * æ›´æ–°APIé…ç½®
     * @param {Object} newConfig - æ–°çš„é…ç½®å¯¹è±¡
     */
    updateConfig(newConfig) {
        if (newConfig.llm) {
            this.apiKey = newConfig.llm.api_key || this.apiKey;
            this.apiUrl = newConfig.llm.api_url || this.apiUrl;
            this.model = newConfig.llm.model || this.model;
            logToTerminal('info', 'LLMå®¢æˆ·ç«¯é…ç½®å·²æ›´æ–°');
        }
    }

    /**
     * è·å–å½“å‰é…ç½®
     * @returns {Object}
     */
    getConfig() {
        return {
            apiUrl: this.apiUrl,
            model: this.model
        };
    }
}

module.exports = { LLMClient };
